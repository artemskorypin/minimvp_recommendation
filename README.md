# Документация по построению рекомандетельной системы
## Описание исходных данных

**events** — датасет с событиями. Колонки:
    
    timestamp — время события (числовой)
    visitorid — идентификатор пользователя (числовой)
    event — тип события (объектовый)
    itemid — идентификатор объекта (числовой)
    transactionid — идентификатор транзакции, если она проходила (числовой)

**category_tree** — файл с деревом категорий.
    
    category_id — идентификатор категорий (числовой)
    parent_id — идентификатор родительской категории (числовой)

**item_properties** — файл с свойствами товаров.

    timestamp — момент записи значения свойства (числовой)
    item_id — идентификатор объекта (числовой)
    property — свойство, кажется, они все, кроме категории, захешированы (объектовый)
    value — значение свойства (объектовый)

## Трансформации исходного датасета для проведения эксперементов

Обученные модели делятся на **две** группы. 
**Первая**, использовала с своем обучении разряженную матрицу пользователь-товар с указанием уровня взаимодействия (не видел, смотрел, добавил в корзину, купил). Матрица была получена на основе таблицы событий. Также был подготовлен маппинг всех пользователей и товаров для получения рекомендаций. **(ALS, LightFM, NCF)**

**Вторая**, использовала в своем обучении таблицу с большим количеством признаков (**31**), переведенных в числовой формат. **Признаки**: айди покупателя, айди товара, год, месяц, день, час, минуты, период дня, день недели, признаки описания тавров (**19**). **Целевой признак бинарный**, отображает наличие покупки. **(LogisticRegression, CatBoostClassifier, XGBClassifier, NCF)**

Таблица используемая в обучении была составлена на основе данных из таблицы событий и таблицы товаров. Временные признаки извлечены из даты события. Признаки описания товаров были получены следующим образом. Отобрали 15 самых популярных свойств товаров, затем переводим таблицу в широкий вид и заполнили пропуски 0 и 'unknown'. Те столбцы, что являлись числовыми нормализовали (логарифмировали), остальные захешировали (HashingEncoder) в 8 столбцов. Большее количество признаков (свойтсв) брать не имеет смысла, так как «новые столбцы» практически все пустые (98-99%) и не добавляют качество в модели.

Из таблицы событий также необходимо удалить столбец «событий» (**подсматриваем в ответ**), столбец «айди транзакций» перевести в бинарный признак (была, не была) (**целевой признак**). 

*Удаление аномалий и неактивных пользователей.* Таблицу событий необходимо отчистить от аномалий, таких как добавление в корзину без просмотра, покупка без просмотра или добавления в корзину. Также уберем из данных мало активных пользователей, тех кто встречается меньше 5 раз. После этого таблицу событий можно объединять с широкоформатной таблицей описания товаров с последующим заполнением пропусков. И проверить чтобы все данные были числовыми.

Разделение данных на тестовую и тренировочную выборку происходит по дате 2015-09-01 (последний месяц). Столбец даты удаляем, он избыточен. 

[Здесь](get_data.ipynb) представлен ноутбук для получения двух наборов данных для обучения.

## Проведенные эксперементы

Проведенные эксперементы также как и модели деляться на две группы. Там где участвовала разряженная матрица пользователь-товар применялся полный перебор значений параметров по сетке. **(ALS, LightFM, NCF)**

В другом случае, попробовали применить подбор параметров через **Optuna**, реулируя максимальное количество моделей для обучения и общее время обучения, чтобы оно было не слишком долгим. Опытным путем понял, что времени обучения в 10 мин вполне хватает. Если увеличивать время обучения, то улучшение результата не гарантировано и скорее всего будет очень не значительным. 

Для дальнейших эксперементов рекомендуется продумать расширенный набор признаков, которые можно использовать, возможно это улучшить качество моделей. Но нужно отслеживать результат обучения моделей, так как, к примеру, **логистическая регресия** выделила в качестве главенствующего признака "**час**". В результате, получили "рекомендации по часам".

Посмотреть проведенные эксперементы можно [здесь](model.ipynb).

## Значение метрик по моделям

### Результаты с использованием матрицы пользователь-товар


| Модель   | Precision@3 |
| -------- | ----------- |
| ALS      | 0.0133      |
| LightFM  | 0.0120      | 
| NCF 	   | 0.0000      | 

### Результаты с использованием другого подхода


| Модель             | Precision@3 |
| ------------------ | ----------- |
| LogisticRegression | 0.0159      |
| CatBoostClassifier | 0.0108      | 
| XGBClassifier 	 | 0.0107      | 
| NCF            	 | 0.0045      | 

Лучшей моделью была выбрана **ALS**.

## Структура сервиса

* app.py — основной Flask-приложение
* AlternatingLeastSquares.pkl — сериализованная модель ALS
* data/ — папка с матрицей взаимодействий и маппингами:
   
    train_matrix.npz — разреженная матрица пользователь–товар \
    *_mapping.npy — отображения ID пользователей и товаров \
    copy_properties_full_long.csv — описание товаров

* templates/index.html — HTML-интерфейс (ввод user_id и вывод топ-3 рекомендаций)
* utils.py — вспомогательные функции: извлечение признаков, описания товаров

Метрики **Prometheus**: 
* общее количество запросов
* время ответа
* использование CPU и памяти

Эти метрики также можно прокинуть в **Grafana**.

## Описание API сервиса

**GET /**

Возвращает HTML-страницу с формой для ввода user_id

**POST /**

Форма запроса: **user_id** — целое положительное число

Логика:
* Если пользователь найден и есть взаимодействия → выдает топ-3 рекомендации с описанием
* Если пользователь не найден или нет взаимодействий → возвращает fallback-рекомендации (популярные товары)
* Если ввод не корректен, то сообщение с просьбой ввести правильное значение

**/metrics**

Нет доступа для обычных пользователей.

Эндпоинт **Prometheus**. Возвращает:
* Общее число запросов (**requests_total**)
* Время обработки (**custom_request_latency_seconds_my**)
* Использование памяти (**memory_usage_mb**)
* Загрузка CPU (**cpu_usage_percent**)

## Внутренняя логика

* Используется обученная модель **ALS** (implicit)
* Модель работает на основе матрицы взаимодействий
* Подбор рекомендаций идёт через model.recommend(...) для заданного user_id
* Если user_id отсутствует или нет истории — выдаются fallback-товары

## Как запустить сервис

### Собираем образ ml-service
docker compose build

### Запускаем контейнер
docker compose up

### Остановка и удаление сервисов
docker compose down

### Поднимутся три сервиса:

    ml-service на порту 5000 — Flask API для рекомендаций

    prometheus на порту 9090 — сбор метрик

    grafana на порту 3000 — визуализация

### Структура сети
Мы явно указали сеть monitoring, и все сервисы подключены к ней, значит:

    ml-service экспортирует только публичный порт 5000

    Prometheus может опрашивать /metrics у ml-service, даже если он недоступен снаружи (внутри сети monitoring)

    Grafana может строить графики на основе Prometheus

## Как прокинуть метрики в Grafana из Prometheus

* Сначала проверяем, что внутри докера все интсрументы работают в рамках одной сети (в моем проекте **monitoring**), это важно, если будите делать подобное сами.
* Убеждаемся, что Prometheus собирает метрики.
* После этого заходим в Grafana под admin/admin, нам предложат сменить пароль, меняем.
* На панеле с лева находим вкладку Dashboards, создаем новый Dashboard и добавляем наш источник данных Prometheus. 
* В Prometheus нам необходимо указать наш адрес http://prometheus:9090 и сохранить изменения.
* Возвращаемся в Dashboard, выбираем Prometheus и начинаем формировать графики метрик.
* Мы будем указывать одну метрику на одном графике. Для этого выбираем нужную нам метрику, к примеру cpu_usage_percent, и нажимаем Run queries. Если все сделано правильно, появиться график метрики из Prometheus.
* Теперь нам необходимо сохранить эту метрику в Dashboard. Для этого даем название нашему графику и нажимаем на Save dashboard (указываем название нашего Dashboard). 
* Для того чтобы добавить следующие метрики, нажимаем на Back to dashboard, затем на Add и Visualization. Повторяем шаги по созданию и сохранению метрики. 


